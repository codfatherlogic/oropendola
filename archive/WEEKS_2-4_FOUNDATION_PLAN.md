# WEEKS 2-4 FOUNDATION PLAN

**Date**: 2025-10-24
**Version**: 3.4.4 ‚Üí 3.5.0
**Duration**: 3 weeks (Weeks 2-4)
**Architecture**: Single backend at https://oropendola.ai

---

## üéØ OVERVIEW

Weeks 2-4 focus on building a solid foundation for Oropendola AI Assistant with:
- **Type Safety**: Selective TypeScript migration for critical files
- **Document Support**: PDF, Word, Excel, HTML processing
- **Global Ready**: Internationalization (i18n) framework
- **Smart Search**: Vector database for code search and memory

**EXCLUDED**: MCP integration (per user request - single backend architecture)

---

## üìÖ TIMELINE

### Week 2: TypeScript & Document Processing
- **Week 2.1**: TypeScript migration (3-4 days)
  - Critical files: Security, Config, Realtime
  - Build system updates
  - Type definitions

- **Week 2.2**: Document Processing (3-4 days)
  - PDF support
  - Word/Excel support
  - HTML parsing
  - Image extraction

### Week 3: Internationalization & Vector DB Foundation
- **Week 3.1**: Internationalization (3-4 days)
  - i18n framework setup
  - English translations
  - 2-3 additional languages
  - RTL support

- **Week 3.2**: Vector Database (3-4 days)
  - Vector storage architecture
  - Embedding generation
  - Semantic search
  - Memory system

### Week 4: Integration & Testing
- **Week 4.1**: Integration (2-3 days)
  - Component integration
  - End-to-end testing
  - Performance optimization

- **Week 4.2**: Documentation & Polish (2-3 days)
  - User documentation
  - API documentation
  - Release preparation

---

## üîß WEEK 2.1: TYPESCRIPT MIGRATION

### Goal
Migrate critical files to TypeScript for better type safety and maintainability.

### Strategy: Selective Migration
**Philosophy**: Don't migrate everything - focus on high-impact files that benefit most from type safety.

### Files to Migrate (Priority Order)

#### Priority 1: Security & Configuration (Week 1 components)
1. **src/security/CommandValidator.js** ‚Üí **CommandValidator.ts**
   - Complex validation logic
   - Benefits from type safety
   - ~280 lines

2. **src/security/RiskAssessor.js** ‚Üí **RiskAssessor.ts**
   - Pattern matching logic
   - Risk level enums
   - ~300 lines

3. **src/config/BackendConfig.js** ‚Üí **BackendConfig.ts**
   - Configuration singleton
   - API endpoint definitions
   - ~250 lines

4. **src/core/RealtimeManagerEnhanced.js** ‚Üí **RealtimeManagerEnhanced.ts**
   - Complex state management
   - Event typing
   - ~370 lines

#### Priority 2: Core Utilities
5. **src/utils/logger.js** ‚Üí **logger.ts** (if exists)
6. **src/utils/errors.js** ‚Üí **errors.ts** (if exists)

#### Priority 3: New Components (Will be TypeScript from start)
- Document processors (Week 2.2)
- i18n system (Week 3.1)
- Vector database client (Week 3.2)

### TypeScript Configuration

**tsconfig.json**:
```json
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "commonjs",
    "lib": ["ES2020"],
    "outDir": "./dist",
    "rootDir": "./",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "allowSyntheticDefaultImports": true,
    "types": ["node", "vscode"]
  },
  "include": [
    "src/**/*.ts",
    "*.ts"
  ],
  "exclude": [
    "node_modules",
    "dist",
    "out",
    "test",
    "webview-ui"
  ]
}
```

### Type Definitions

**src/types/index.ts**:
```typescript
// Command validation types
export interface CommandValidationResult {
  allowed: boolean;
  requiresConfirmation: boolean;
  reason: string;
  riskLevel: RiskLevel;
  sanitized: string;
}

export type RiskLevel = 'low' | 'medium' | 'high';

export interface RiskPattern {
  pattern: RegExp;
  reason: string;
}

export interface RiskAssessment {
  level: RiskLevel;
  reason: string;
  details: string[];
  score: number;
}

// Backend configuration types
export interface BackendEndpoints {
  login: string;
  logout: string;
  verifySession: string;
  chat: string;
  chatStream: string;
  chatHistory: string;
  userInfo: string;
  userSettings: string;
  updateSettings: string;
  checkSubscription: string;
  subscriptionInfo: string;
  indexWorkspace: string;
  searchCode: string;
  workspaceMemory: string;
  uploadFile: string;
  analyzeFile: string;
  socketIO: string;
  webSocket: string;
}

// Realtime connection types
export type ConnectionState =
  | 'disconnected'
  | 'connecting'
  | 'connected'
  | 'reconnecting'
  | 'error';

export interface ConnectionStateData {
  state: ConnectionState;
  attempt?: number;
  maxAttempts?: number;
  delay?: number;
  error?: string;
  giveUp?: boolean;
}

export interface RealtimeMessage {
  type: string;
  data: any;
  timestamp: number;
}

// Document processing types (for Week 2.2)
export type DocumentType = 'pdf' | 'docx' | 'xlsx' | 'html' | 'txt' | 'md';

export interface DocumentMetadata {
  type: DocumentType;
  size: number;
  pages?: number;
  wordCount?: number;
  language?: string;
  created?: Date;
  modified?: Date;
}

export interface ProcessedDocument {
  content: string;
  metadata: DocumentMetadata;
  images?: string[];
  tables?: any[];
  links?: string[];
}

// i18n types (for Week 3.1)
export type SupportedLanguage = 'en' | 'es' | 'fr' | 'de' | 'ja' | 'zh';

export interface TranslationKeys {
  [key: string]: string | TranslationKeys;
}

// Vector database types (for Week 3.2)
export interface VectorEntry {
  id: string;
  vector: number[];
  metadata: Record<string, any>;
  content: string;
}

export interface SearchResult {
  id: string;
  content: string;
  score: number;
  metadata: Record<string, any>;
}
```

### Build System Updates

**Update esbuild.config.js** to support TypeScript:
```javascript
// Add TypeScript plugin
const extensionConfig = {
  // ... existing config
  loader: {
    '.ts': 'ts',
    '.tsx': 'tsx'
  }
};
```

**Update package.json**:
```json
{
  "scripts": {
    "build": "tsc && node esbuild.config.js",
    "build:production": "tsc && NODE_ENV=production node esbuild.config.js",
    "typecheck": "tsc --noEmit",
    "watch": "tsc --watch & node esbuild.config.js --watch"
  },
  "devDependencies": {
    "typescript": "^5.3.0",
    "@types/node": "^20.10.0",
    "@types/vscode": "^1.85.0",
    "@types/socket.io-client": "^3.0.0"
  }
}
```

### Migration Strategy

**For each file**:
1. Create `.ts` version alongside `.js`
2. Add type annotations incrementally
3. Run `tsc --noEmit` to check types
4. Update imports in other files
5. Test thoroughly
6. Delete `.js` file once verified

**Estimated Time**: 3-4 days
**Files to Migrate**: 4-6 critical files (~1,200 lines)
**Test Coverage**: Maintain 100% for migrated files

---

## üìÑ WEEK 2.2: DOCUMENT PROCESSING

### Goal
Add support for processing PDF, Word, Excel, and HTML documents for AI analysis.

### Architecture

```
src/documents/
‚îú‚îÄ‚îÄ DocumentProcessor.ts         # Main processor
‚îú‚îÄ‚îÄ processors/
‚îÇ   ‚îú‚îÄ‚îÄ PdfProcessor.ts          # PDF support
‚îÇ   ‚îú‚îÄ‚îÄ WordProcessor.ts         # DOCX support
‚îÇ   ‚îú‚îÄ‚îÄ ExcelProcessor.ts        # XLSX support
‚îÇ   ‚îú‚îÄ‚îÄ HtmlProcessor.ts         # HTML support
‚îÇ   ‚îî‚îÄ‚îÄ TextProcessor.ts         # TXT/MD support
‚îú‚îÄ‚îÄ extractors/
‚îÇ   ‚îú‚îÄ‚îÄ ImageExtractor.ts        # Extract images
‚îÇ   ‚îú‚îÄ‚îÄ TableExtractor.ts        # Extract tables
‚îÇ   ‚îî‚îÄ‚îÄ MetadataExtractor.ts     # Extract metadata
‚îî‚îÄ‚îÄ __tests__/
    ‚îî‚îÄ‚îÄ DocumentProcessor.test.ts
```

### Libraries

#### PDF Processing
```bash
npm install pdf-parse pdf-lib
```
**Features**:
- Text extraction
- Image extraction
- Page count
- Metadata

#### Word Processing
```bash
npm install mammoth
```
**Features**:
- DOCX ‚Üí HTML/Text
- Style preservation
- Image extraction

#### Excel Processing
```bash
npm install xlsx
```
**Features**:
- Sheet reading
- Cell formatting
- Chart data extraction

#### HTML Processing
```bash
npm install cheerio
```
**Features**:
- DOM parsing
- Text extraction
- Link extraction
- Image extraction

### Implementation

**src/documents/DocumentProcessor.ts**:
```typescript
import * as vscode from 'vscode';
import { DocumentType, ProcessedDocument } from '../types';
import { PdfProcessor } from './processors/PdfProcessor';
import { WordProcessor } from './processors/WordProcessor';
import { ExcelProcessor } from './processors/ExcelProcessor';
import { HtmlProcessor } from './processors/HtmlProcessor';
import { TextProcessor } from './processors/TextProcessor';

export class DocumentProcessor {
  private processors: Map<DocumentType, any>;

  constructor() {
    this.processors = new Map([
      ['pdf', new PdfProcessor()],
      ['docx', new WordProcessor()],
      ['xlsx', new ExcelProcessor()],
      ['html', new HtmlProcessor()],
      ['txt', new TextProcessor()],
      ['md', new TextProcessor()]
    ]);
  }

  async process(filePath: string): Promise<ProcessedDocument> {
    const type = this.detectType(filePath);
    const processor = this.processors.get(type);

    if (!processor) {
      throw new Error(`Unsupported document type: ${type}`);
    }

    return await processor.process(filePath);
  }

  private detectType(filePath: string): DocumentType {
    const ext = filePath.split('.').pop()?.toLowerCase();

    switch (ext) {
      case 'pdf': return 'pdf';
      case 'docx': return 'docx';
      case 'doc': return 'docx';
      case 'xlsx': return 'xlsx';
      case 'xls': return 'xlsx';
      case 'html': return 'html';
      case 'htm': return 'html';
      case 'txt': return 'txt';
      case 'md': return 'md';
      default: throw new Error(`Unknown file extension: ${ext}`);
    }
  }

  getSupportedTypes(): DocumentType[] {
    return Array.from(this.processors.keys());
  }
}
```

**VS Code Integration**:
```typescript
// Add command to process documents
vscode.commands.registerCommand('oropendola.processDocument', async (uri: vscode.Uri) => {
  const processor = new DocumentProcessor();
  const result = await processor.process(uri.fsPath);

  // Send to AI for analysis
  await sendToAI({
    type: 'document_analysis',
    content: result.content,
    metadata: result.metadata
  });
});
```

### User Features

1. **Right-click Context Menu**:
   - "Analyze Document with Oropendola AI"
   - Appears on PDF, Word, Excel, HTML files

2. **Drag & Drop**:
   - Drag document into chat
   - Auto-process and analyze

3. **Bulk Processing**:
   - Select multiple documents
   - Process all at once

4. **Image Support**:
   - Extract images from documents
   - Send images to multimodal AI

### Backend Integration

**New endpoints needed** (backend development):
```typescript
// Upload document
POST /api/method/oropendola.documents.upload
Body: { file: binary, type: string }
Response: { document_id: string }

// Analyze document
POST /api/method/oropendola.documents.analyze
Body: { document_id: string, content: string, metadata: object }
Response: { analysis: string, summary: string, insights: [] }
```

**Estimated Time**: 3-4 days
**Backend Work**: 2 new endpoints
**Test Coverage**: 80%+ for document processors

---

## üåç WEEK 3.1: INTERNATIONALIZATION (i18n)

### Goal
Add multi-language support for global users.

### Architecture

```
src/i18n/
‚îú‚îÄ‚îÄ I18nManager.ts               # Main i18n system
‚îú‚îÄ‚îÄ locales/
‚îÇ   ‚îú‚îÄ‚îÄ en.json                  # English (default)
‚îÇ   ‚îú‚îÄ‚îÄ es.json                  # Spanish
‚îÇ   ‚îú‚îÄ‚îÄ fr.json                  # French
‚îÇ   ‚îú‚îÄ‚îÄ de.json                  # German
‚îÇ   ‚îú‚îÄ‚îÄ ja.json                  # Japanese
‚îÇ   ‚îî‚îÄ‚îÄ zh.json                  # Chinese
‚îú‚îÄ‚îÄ formatters/
‚îÇ   ‚îú‚îÄ‚îÄ DateFormatter.ts         # Date formatting
‚îÇ   ‚îú‚îÄ‚îÄ NumberFormatter.ts       # Number formatting
‚îÇ   ‚îî‚îÄ‚îÄ CurrencyFormatter.ts     # Currency formatting
‚îî‚îÄ‚îÄ __tests__/
    ‚îî‚îÄ‚îÄ I18nManager.test.ts
```

### Library

```bash
npm install i18next i18next-fs-backend
npm install -D @types/i18next
```

### Implementation

**src/i18n/I18nManager.ts**:
```typescript
import i18next from 'i18next';
import Backend from 'i18next-fs-backend';
import * as vscode from 'vscode';
import * as path from 'path';

export class I18nManager {
  private static instance: I18nManager;
  private currentLanguage: string = 'en';

  private constructor() {}

  static getInstance(): I18nManager {
    if (!I18nManager.instance) {
      I18nManager.instance = new I18nManager();
    }
    return I18nManager.instance;
  }

  async initialize(extensionPath: string): Promise<void> {
    await i18next
      .use(Backend)
      .init({
        lng: this.detectLanguage(),
        fallbackLng: 'en',
        backend: {
          loadPath: path.join(extensionPath, 'src/i18n/locales/{{lng}}.json')
        },
        interpolation: {
          escapeValue: false
        }
      });

    this.currentLanguage = i18next.language;
  }

  t(key: string, options?: any): string {
    return i18next.t(key, options);
  }

  async changeLanguage(language: string): Promise<void> {
    await i18next.changeLanguage(language);
    this.currentLanguage = language;

    // Update VS Code configuration
    const config = vscode.workspace.getConfiguration('oropendola');
    await config.update('language', language, vscode.ConfigurationTarget.Global);
  }

  getCurrentLanguage(): string {
    return this.currentLanguage;
  }

  private detectLanguage(): string {
    // Try VS Code configuration
    const config = vscode.workspace.getConfiguration('oropendola');
    const configured = config.get<string>('language');
    if (configured) return configured;

    // Try VS Code display language
    const vsCodeLang = vscode.env.language;
    const lang = vsCodeLang.split('-')[0];

    // Check if supported
    const supported = ['en', 'es', 'fr', 'de', 'ja', 'zh'];
    return supported.includes(lang) ? lang : 'en';
  }

  getSupportedLanguages(): string[] {
    return ['en', 'es', 'fr', 'de', 'ja', 'zh'];
  }
}

// Export singleton instance
export const i18n = I18nManager.getInstance();

// Helper function for easy translation
export function t(key: string, options?: any): string {
  return i18n.t(key, options);
}
```

### Translation Files

**src/i18n/locales/en.json**:
```json
{
  "common": {
    "yes": "Yes",
    "no": "No",
    "cancel": "Cancel",
    "ok": "OK",
    "save": "Save",
    "delete": "Delete",
    "edit": "Edit",
    "loading": "Loading...",
    "error": "Error",
    "success": "Success"
  },
  "commands": {
    "validation": {
      "title": "Command Validation",
      "risky": "This command is risky",
      "confirm": "Are you sure you want to execute this command?",
      "blocked": "Command blocked for security",
      "allowed": "Command allowed"
    }
  },
  "connection": {
    "connecting": "Connecting to Oropendola AI...",
    "connected": "Connected successfully",
    "disconnected": "Disconnected from server",
    "reconnecting": "Reconnecting... (Attempt {{attempt}} of {{max}})",
    "failed": "Connection failed after {{attempts}} attempts"
  },
  "documents": {
    "processing": "Processing document...",
    "processed": "Document processed successfully",
    "failed": "Failed to process document",
    "unsupported": "Unsupported document type: {{type}}",
    "analyzing": "Analyzing document with AI..."
  },
  "settings": {
    "title": "Oropendola AI Settings",
    "language": "Language",
    "theme": "Theme",
    "security": "Security Settings",
    "advanced": "Advanced"
  }
}
```

**src/i18n/locales/es.json** (Spanish):
```json
{
  "common": {
    "yes": "S√≠",
    "no": "No",
    "cancel": "Cancelar",
    "ok": "Aceptar",
    "save": "Guardar",
    "delete": "Eliminar",
    "edit": "Editar",
    "loading": "Cargando...",
    "error": "Error",
    "success": "√âxito"
  },
  "commands": {
    "validation": {
      "title": "Validaci√≥n de Comando",
      "risky": "Este comando es peligroso",
      "confirm": "¬øEst√° seguro de que desea ejecutar este comando?",
      "blocked": "Comando bloqueado por seguridad",
      "allowed": "Comando permitido"
    }
  },
  "connection": {
    "connecting": "Conectando a Oropendola AI...",
    "connected": "Conectado exitosamente",
    "disconnected": "Desconectado del servidor",
    "reconnecting": "Reconectando... (Intento {{attempt}} de {{max}})",
    "failed": "Conexi√≥n fall√≥ despu√©s de {{attempts}} intentos"
  }
}
```

### Usage Examples

```typescript
import { t } from './i18n/I18nManager';

// Simple translation
vscode.window.showInformationMessage(t('connection.connected'));

// Translation with variables
vscode.window.showWarningMessage(
  t('connection.reconnecting', { attempt: 3, max: 10 })
);

// In command validation
const message = t('commands.validation.risky');
const confirm = t('commands.validation.confirm');
```

### VS Code Settings

**package.json configuration**:
```json
{
  "contributes": {
    "configuration": {
      "properties": {
        "oropendola.language": {
          "type": "string",
          "enum": ["en", "es", "fr", "de", "ja", "zh"],
          "enumDescriptions": [
            "English",
            "Espa√±ol",
            "Fran√ßais",
            "Deutsch",
            "Êó•Êú¨Ë™û",
            "‰∏≠Êñá"
          ],
          "default": "en",
          "description": "Display language for Oropendola AI Assistant"
        }
      }
    },
    "commands": [
      {
        "command": "oropendola.changeLanguage",
        "title": "Oropendola: Change Language"
      }
    ]
  }
}
```

### RTL Support (Arabic, Hebrew)

```typescript
// Detect RTL languages
function isRTL(language: string): boolean {
  return ['ar', 'he', 'fa'].includes(language);
}

// Apply RTL styles to webview
if (isRTL(currentLanguage)) {
  webview.html = webview.html.replace(
    '<html',
    '<html dir="rtl"'
  );
}
```

**Estimated Time**: 3-4 days
**Languages**: English + 2-3 additional (Spanish, French, German priority)
**Backend Work**: None - frontend only
**Test Coverage**: 70%+

---

## üîç WEEK 3.2: VECTOR DATABASE INTEGRATION

### Goal
Add semantic search and memory system using vector embeddings.

### Architecture Choice

**Option 1: Backend-Hosted (Recommended)**
- Store vectors on Oropendola AI backend
- Frappe backend manages vector storage
- Frontend sends text, backend returns embeddings

**Option 2: Client-Side (Lighter)**
- Use local vector storage
- Generate embeddings client-side
- Store in IndexedDB or local files

**Recommendation**: **Option 1** (Backend-hosted) for better performance and centralized management.

### Architecture

```
src/vector/
‚îú‚îÄ‚îÄ VectorDBClient.ts            # Main client
‚îú‚îÄ‚îÄ EmbeddingGenerator.ts        # Generate embeddings
‚îú‚îÄ‚îÄ SemanticSearch.ts            # Search functionality
‚îú‚îÄ‚îÄ MemoryManager.ts             # Long-term memory
‚îú‚îÄ‚îÄ storage/
‚îÇ   ‚îú‚îÄ‚îÄ VectorStorage.ts         # Storage interface
‚îÇ   ‚îî‚îÄ‚îÄ BackendStorage.ts        # Backend implementation
‚îî‚îÄ‚îÄ __tests__/
    ‚îî‚îÄ‚îÄ VectorDBClient.test.ts
```

### Implementation

**src/vector/VectorDBClient.ts**:
```typescript
import { BackendConfig } from '../config/BackendConfig';
import { VectorEntry, SearchResult } from '../types';

export class VectorDBClient {
  private backendConfig: BackendConfig;

  constructor() {
    this.backendConfig = BackendConfig.getInstance();
  }

  /**
   * Index code file for semantic search
   */
  async indexFile(filePath: string, content: string): Promise<string> {
    const response = await fetch(
      this.backendConfig.getApiUrl('/api/method/oropendola.vector.index'),
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          file_path: filePath,
          content: content,
          metadata: {
            indexed_at: new Date().toISOString()
          }
        })
      }
    );

    const data = await response.json();
    return data.message.entry_id;
  }

  /**
   * Semantic search across indexed files
   */
  async search(query: string, limit: number = 10): Promise<SearchResult[]> {
    const response = await fetch(
      this.backendConfig.getApiUrl('/api/method/oropendola.vector.search'),
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          query: query,
          limit: limit
        })
      }
    );

    const data = await response.json();
    return data.message.results;
  }

  /**
   * Store conversation in long-term memory
   */
  async storeMemory(conversation: any): Promise<void> {
    await fetch(
      this.backendConfig.getApiUrl('/api/method/oropendola.vector.store_memory'),
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          conversation: conversation,
          timestamp: new Date().toISOString()
        })
      }
    );
  }

  /**
   * Retrieve relevant memories for context
   */
  async retrieveMemories(query: string, limit: number = 5): Promise<any[]> {
    const response = await fetch(
      this.backendConfig.getApiUrl('/api/method/oropendola.vector.retrieve_memories'),
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          query: query,
          limit: limit
        })
      }
    );

    const data = await response.json();
    return data.message.memories;
  }
}
```

### Features

#### 1. Semantic Code Search
```typescript
// Find similar code across workspace
const results = await vectorDB.search("authentication logic");
// Returns: Files containing auth-related code, ranked by similarity
```

#### 2. Long-term Memory
```typescript
// Store important conversations
await vectorDB.storeMemory({
  messages: conversation.messages,
  summary: "User implemented OAuth2 authentication",
  tags: ["auth", "security"]
});

// Retrieve relevant memories
const memories = await vectorDB.retrieveMemories("how did I implement auth?");
// Returns: Previous conversations about authentication
```

#### 3. Intelligent Context
```typescript
// Get relevant context for AI
const context = await vectorDB.search(userQuery, 5);
// AI receives relevant code snippets automatically
```

### Backend Requirements

**New endpoints needed**:

```python
# In Oropendola AI backend (Frappe)

@frappe.whitelist()
def index(file_path, content, metadata):
    """Index file content for vector search"""
    # Generate embeddings using OpenAI/sentence-transformers
    embedding = generate_embedding(content)

    # Store in vector database (Pinecone/Weaviate/ChromaDB)
    vector_db.insert({
        'id': generate_id(),
        'vector': embedding,
        'content': content,
        'file_path': file_path,
        'metadata': metadata
    })

    return {'entry_id': entry_id}

@frappe.whitelist()
def search(query, limit=10):
    """Semantic search across indexed files"""
    # Generate query embedding
    query_embedding = generate_embedding(query)

    # Search vector database
    results = vector_db.search(query_embedding, limit)

    return {'results': results}

@frappe.whitelist()
def store_memory(conversation, timestamp):
    """Store conversation in long-term memory"""
    # Generate summary
    summary = summarize_conversation(conversation)

    # Store with embedding
    embedding = generate_embedding(summary)
    vector_db.insert({
        'type': 'memory',
        'conversation': conversation,
        'summary': summary,
        'vector': embedding,
        'timestamp': timestamp
    })

@frappe.whitelist()
def retrieve_memories(query, limit=5):
    """Retrieve relevant memories"""
    query_embedding = generate_embedding(query)
    memories = vector_db.search(query_embedding, limit, type='memory')
    return {'memories': memories}
```

**Backend dependencies**:
```bash
# On Oropendola AI server
pip install sentence-transformers
pip install chromadb  # or pinecone-client, weaviate-client
```

### Integration with Chat

```typescript
// Before sending message to AI
const relevantContext = await vectorDB.search(userMessage, 3);
const relevantMemories = await vectorDB.retrieveMemories(userMessage, 2);

// Send enhanced message
await sendToAI({
  message: userMessage,
  context: relevantContext,
  memories: relevantMemories
});
```

**Estimated Time**: 3-4 days frontend, 2-3 days backend
**Backend Work**: 4 new endpoints, vector database setup
**Test Coverage**: 70%+

---

## üì¶ DELIVERABLES

### Week 2
- ‚úÖ 4-6 critical files migrated to TypeScript
- ‚úÖ TypeScript build system configured
- ‚úÖ Type definitions for all core systems
- ‚úÖ PDF, Word, Excel, HTML document processing
- ‚úÖ Document analysis commands in VS Code

### Week 3
- ‚úÖ i18n framework with 3-5 languages
- ‚úÖ Language switcher in settings
- ‚úÖ All UI strings translated
- ‚úÖ Vector database client
- ‚úÖ Semantic code search
- ‚úÖ Long-term memory system

### Week 4
- ‚úÖ All components integrated
- ‚úÖ End-to-end tests passing
- ‚úÖ Performance benchmarks met
- ‚úÖ User documentation
- ‚úÖ API documentation
- ‚úÖ Release v3.5.0

---

## üéØ SUCCESS METRICS

### Code Quality
- TypeScript coverage: 30%+ of codebase
- Type errors: 0
- Test coverage: 75%+
- Build time: <2 minutes

### Functionality
- Document processing: 95%+ accuracy
- i18n: 3+ languages supported
- Vector search: <500ms response time
- Memory retrieval: <300ms response time

### User Experience
- Document analysis: 1-click easy
- Language switching: Instant
- Semantic search: Accurate results
- Context awareness: Relevant suggestions

---

## ‚ö†Ô∏è RISKS & MITIGATION

### Risk 1: TypeScript Migration Complexity
**Impact**: High
**Probability**: Medium
**Mitigation**:
- Selective migration (not everything)
- Incremental approach
- Thorough testing at each step

### Risk 2: Document Processing Accuracy
**Impact**: High
**Probability**: Medium
**Mitigation**:
- Use battle-tested libraries
- Extensive testing with real documents
- Graceful error handling

### Risk 3: Backend Vector Database Setup
**Impact**: High
**Probability**: Medium
**Mitigation**:
- Start with ChromaDB (simplest)
- Provide detailed backend setup guide
- Fallback to local storage if backend not ready

### Risk 4: Translation Quality
**Impact**: Medium
**Probability**: Medium
**Mitigation**:
- Start with English only
- Add languages incrementally
- Use professional translation services

---

## üìä EFFORT ESTIMATION

| Task | Frontend Days | Backend Days | Total |
|------|---------------|--------------|-------|
| TypeScript Migration | 3-4 | 0 | 3-4 |
| Document Processing | 3-4 | 1-2 | 4-6 |
| Internationalization | 3-4 | 0 | 3-4 |
| Vector Database | 3-4 | 2-3 | 5-7 |
| Integration & Testing | 2-3 | 1 | 3-4 |
| **Total** | **14-19 days** | **4-6 days** | **18-25 days** |

**Team**: 1 frontend developer, 1 backend developer
**Duration**: 3 weeks (15 working days)
**Buffer**: 3-10 days for unexpected issues

---

## üöÄ GETTING STARTED

### Immediate Next Steps

1. **Review this plan** - Approve or suggest changes
2. **Backend preparation** - Set up vector database on backend
3. **Install dependencies** - TypeScript, document processing libs
4. **Start TypeScript migration** - Begin with CommandValidator.ts

### Prerequisites

**Frontend**:
- Week 1 complete ‚úÖ
- Node.js 16+ ‚úÖ
- VS Code API knowledge ‚úÖ

**Backend**:
- Frappe framework ‚úÖ
- Python 3.8+ ‚úÖ
- Access to add new endpoints ‚úÖ
- Vector database (ChromaDB/Pinecone) ‚ùì

**Skills**:
- TypeScript (learning curve acceptable)
- Document processing (libraries handle complexity)
- i18n (straightforward with i18next)
- Vector embeddings (backend handles complexity)

---

## üìû QUESTIONS TO RESOLVE

Before starting, please clarify:

1. **Backend Vector Database**: Do you want to set up ChromaDB on backend, or should we use a cloud service like Pinecone?

2. **Languages Priority**: Which languages should we support first after English?
   - Spanish (ES)? ‚úì Likely
   - French (FR)? ‚úì Likely
   - German (DE)? ‚úì Likely
   - Japanese (JA)?
   - Chinese (ZH)?

3. **Document Processing Scope**: Any specific document types beyond PDF, Word, Excel, HTML?

4. **TypeScript Pace**: Should we migrate more files than planned, or stick to selective approach?

5. **Timeline Flexibility**: Is 3 weeks firm, or can we extend if needed?

---

**Created By**: Claude (Oropendola AI Assistant)
**Date**: 2025-10-24
**Status**: üìã **PLAN READY FOR APPROVAL**

**Next Action**: Awaiting your approval to begin Week 2.1 (TypeScript Migration)
