# Backend Fix Implementation Guide
**Date**: 2025-10-23
**Priority**: üî¥ CRITICAL
**Time Required**: 30 minutes
**Impact**: HIGH - Fixes entire tool calling system

---

## üéØ Executive Summary

Your backend correctly **parses** tool calls but **doesn't return them** in the response sent to the frontend.

**Problem:**
```python
# Backend sends this:
{
    "content": "I'll create a file...```tool_call\n{\"action\": \"create_file\"}```",
    # Missing: tool_calls array!
}
```

**Solution:**
```python
# Backend should send this:
{
    "content": "I'll create a file",  # ‚úÖ Cleaned
    "tool_calls": [{"action": "create_file", ...}],  # ‚úÖ Array
}
```

**Fix Required:** Add 5-10 lines to `chat_completion` endpoint

---

## üìã Current State Analysis

### ‚úÖ What Works

1. **Tool Call Parsing** - Working perfectly
   ```python
   # Line 5505: ai_assistant/api/__init__.py
   def _parse_tool_calls(response_text: str) -> List[Dict[str, Any]]:
       pattern = r'```tool_call\s*\n(.*?)\n```'
       matches = re.findall(pattern, response_text, re.DOTALL)
       # ... parses correctly ‚úÖ
   ```

2. **Tool Call Execution** - Working correctly
   ```python
   # Lines 1460, 1846, 3301
   tool_calls = _parse_tool_calls(ai_response)
   # ... executes correctly ‚úÖ
   ```

3. **Tool Call Stripping** - Already implemented
   ```python
   # Lines 246, 1562
   clean_response = re.sub(r'```tool_call\s*\n.*?\n```', '', ai_response, ...)
   # ... strips correctly ‚úÖ
   ```

### ‚ùå What's Broken

**The `chat_completion` endpoint doesn't include `tool_calls` in response:**

```python
# Current (BROKEN):
return {
    'success': True,
    'role': 'assistant',
    'content': ai_response_text,  # ‚ùå Still has tool_call blocks
    # Missing: 'tool_calls': tool_calls
}
```

---

## üîß The Fix

### Location
**File:** `ai_assistant/api/__init__.py`
**Function:** `chat_completion` (around line 3300)
**Endpoint:** `/api/method/ai_assistant.api.chat_completion`

### Step 1: Add Strip Function (if not present)

```python
import re

def strip_tool_call_blocks(text):
    """
    Remove all ```tool_call blocks from AI response text

    Args:
        text (str): AI response with embedded tool calls

    Returns:
        str: Clean text without tool_call blocks
    """
    if not text:
        return text

    # Pattern to match tool_call blocks
    pattern = r'```tool_call\s*\n.*?\n```'

    # Remove all tool_call blocks
    cleaned_text = re.sub(pattern, '', text, flags=re.DOTALL)

    # Clean up excessive newlines
    cleaned_text = re.sub(r'\n{3,}', '\n\n', cleaned_text)

    # Trim whitespace
    return cleaned_text.strip()
```

### Step 2: Update chat_completion Function

**Find this section** (around line 3301):

```python
@frappe.whitelist(allow_guest=False)
def chat_completion(messages=None, conversation_id=None, mode='agent', context=None):
    """Main chat completion endpoint"""

    try:
        # ... existing code to call AI model ...

        ai_response_text = call_ai_model(messages, mode, context)

        if mode == 'agent':
            tool_calls = _parse_tool_calls(ai_response_text)

            if tool_calls:
                frappe.logger().info(f"üîß Agent mode: Detected {len(tool_calls)} tool call(s)")

                # ... existing tool execution code ...

        # ‚ùå CURRENT BROKEN RETURN
        return {
            'success': True,
            'role': 'assistant',
            'content': ai_response_text,
            'conversation_id': conversation_id,
            'model': model_used,
            'usage': usage_stats
        }

    except Exception as e:
        frappe.logger().error(f"[Chat API] Error: {str(e)}")
        return {'success': False, 'error': str(e)}
```

**Replace with:**

```python
@frappe.whitelist(allow_guest=False)
def chat_completion(messages=None, conversation_id=None, mode='agent', context=None):
    """Main chat completion endpoint"""

    try:
        # ... existing code to call AI model ...

        ai_response_text = call_ai_model(messages, mode, context)

        # Initialize tool_calls as empty array
        tool_calls = []

        if mode == 'agent':
            tool_calls = _parse_tool_calls(ai_response_text)

            if tool_calls:
                frappe.logger().info(f"üîß Agent mode: Detected {len(tool_calls)} tool call(s)")

                # ... existing tool execution code ...

        # ‚ú® NEW: Clean content if tool calls present
        if mode == 'agent' and tool_calls:
            clean_content = strip_tool_call_blocks(ai_response_text)
            frappe.logger().info(f"[Chat API] Cleaned content: {len(ai_response_text)} ‚Üí {len(clean_content)} chars")
        else:
            clean_content = ai_response_text

        # ‚úÖ FIXED RETURN - Include tool_calls array
        return {
            'success': True,
            'role': 'assistant',
            'content': clean_content,          # ‚úÖ Cleaned text
            'tool_calls': tool_calls,          # ‚úÖ Parsed array
            'conversation_id': conversation_id,
            'model': model_used,
            'usage': usage_stats
        }

    except Exception as e:
        frappe.logger().error(f"[Chat API] Error: {str(e)}")
        return {'success': False, 'error': str(e)}
```

---

## üì¶ Complete Implementation

Here's the complete code to add/modify:

```python
# ==============================================================================
# ADD THIS FUNCTION (if not already present)
# ==============================================================================

def strip_tool_call_blocks(text):
    """Remove ```tool_call blocks from AI response"""
    if not text:
        return text

    import re

    pattern = r'```tool_call\s*\n.*?\n```'
    cleaned_text = re.sub(pattern, '', text, flags=re.DOTALL)
    cleaned_text = re.sub(r'\n{3,}', '\n\n', cleaned_text)

    return cleaned_text.strip()

# ==============================================================================
# MODIFY chat_completion FUNCTION
# ==============================================================================

@frappe.whitelist(allow_guest=False)
def chat_completion(messages=None, conversation_id=None, mode='agent', context=None):
    """
    Main chat completion endpoint with tool call support

    Returns response with cleaned content and parsed tool_calls array
    """
    try:
        # Parse input (existing code)
        if messages and isinstance(messages, str):
            messages = json.loads(messages)

        if context and isinstance(context, str):
            context = json.loads(context)

        if not messages:
            frappe.throw("Messages required")

        frappe.logger().info(f"[Chat API] Processing request: mode={mode}, messages={len(messages)}")

        # Call AI model (your existing code)
        # This returns the raw AI response with tool_call blocks embedded
        ai_response_text = call_your_ai_model(messages, mode, context)

        frappe.logger().info(f"[Chat API] Raw response: {len(ai_response_text)} chars")

        # Initialize tool_calls array
        tool_calls = []

        # Parse tool calls in agent mode
        if mode == 'agent':
            tool_calls = _parse_tool_calls(ai_response_text)

            if tool_calls:
                frappe.logger().info(f"[Chat API] Detected {len(tool_calls)} tool call(s)")

                # Execute tools if needed (your existing code)
                # ... tool execution logic ...

        # Clean content if tool calls present
        if mode == 'agent' and tool_calls:
            clean_content = strip_tool_call_blocks(ai_response_text)
            frappe.logger().info(f"[Chat API] Cleaned: {len(ai_response_text)} ‚Üí {len(clean_content)} chars")
        else:
            clean_content = ai_response_text

        # Return response with tool_calls array
        return {
            'success': True,
            'role': 'assistant',
            'content': clean_content,          # Cleaned text
            'tool_calls': tool_calls,          # Parsed array
            'conversation_id': conversation_id or frappe.generate_hash(length=12),
            'model': model_used if 'model_used' in locals() else 'unknown',
            'usage': usage_stats if 'usage_stats' in locals() else {}
        }

    except Exception as e:
        frappe.logger().error(f"[Chat API] Error: {str(e)}")
        import traceback
        frappe.logger().error(traceback.format_exc())

        return {
            'success': False,
            'error': str(e)
        }
```

---

## üöÄ Deployment Steps

### 1. SSH to Backend

```bash
ssh your_username@oropendola.ai
cd ~/frappe-bench/apps/ai_assistant/ai_assistant/
```

### 2. Backup Current Code

```bash
cp api/__init__.py api/__init__.py.backup.$(date +%Y%m%d_%H%M%S)
ls -lh api/__init__.py.backup.*
```

### 3. Edit api/__init__.py

```bash
nano api/__init__.py
```

Or use your preferred editor:
```bash
vim api/__init__.py
# or
code api/__init__.py
```

### 4. Apply Changes

**Find the `chat_completion` function** (around line 3300):
```bash
# In nano:
Ctrl+W ‚Üí search for "def chat_completion"

# In vim:
/def chat_completion
```

**Add the changes shown above:**
1. Add `strip_tool_call_blocks()` function (if not present)
2. Update `chat_completion()` return statement to include:
   - Clean content (stripped of tool_call blocks)
   - `tool_calls` array

### 5. Verify Changes

```bash
# Check if strip_tool_call_blocks exists
grep -n "def strip_tool_call_blocks" api/__init__.py

# Check if chat_completion returns tool_calls
grep -A 10 "return {" api/__init__.py | grep -A 8 "'success': True" | grep tool_calls
```

Expected output:
```
'tool_calls': tool_calls,
```

### 6. Restart Backend

```bash
cd ~/frappe-bench
bench restart
```

### 7. Monitor Logs

```bash
tail -f ~/frappe-bench/logs/oropendola.ai.log
```

Look for these lines after sending a message:
```
[Chat API] Detected 1 tool call(s)
[Chat API] Cleaned: 523 ‚Üí 87 chars
```

---

## ‚úÖ Testing

### Test 1: Send Message in VS Code

1. Open Oropendola extension in VS Code
2. Send message: "Create a file called test.py with hello world"
3. Check backend logs

**Expected backend logs:**
```
[Chat API] Processing request: mode=agent, messages=2
[Chat API] Raw response: 523 chars
[Chat API] Detected 1 tool call(s)
[Chat API] Cleaned: 523 ‚Üí 87 chars
```

**Expected frontend logs:**
```
[Extension Host] üîß Backend returned 1 tool_call(s) in response
[Extension Host] üìÇ File changes: 1 files affected
```

**Expected behavior:**
- ‚úÖ File `test.py` is created
- ‚úÖ Chat shows clean message (no ```tool_call blocks)
- ‚úÖ No errors in logs

### Test 2: Verify Response Structure

Check the actual response in frontend logs:

```
[Extension Host] üîç Response data: {
  "message": {
    "content": "I'll create a test.py file for you",  ‚úÖ Clean
    "tool_calls": [                                    ‚úÖ Array
      {"action": "create_file", "path": "test.py", ...}
    ]
  }
}
```

---

## üêõ Troubleshooting

### Issue 1: Still seeing `tool_call` blocks in chat

**Symptom:**
```
AI: I'll create...

```tool_call
{"action": "create_file"}
```

Done!
```

**Cause:** `strip_tool_call_blocks()` not being called

**Fix:**
1. Verify function exists: `grep "def strip_tool_call_blocks" api/__init__.py`
2. Verify it's called: `grep "strip_tool_call_blocks(ai_response" api/__init__.py`
3. Check logs for "Cleaned:" message

### Issue 2: Frontend still shows 0 tool_calls

**Symptom:**
```
[Extension Host] üîß Backend returned 0 tool_call(s) in response
```

**Cause:** `tool_calls` not in return statement

**Fix:**
1. Check return statement:
   ```bash
   grep -A 10 "return {" api/__init__.py | grep tool_calls
   ```
2. Should output: `'tool_calls': tool_calls,`
3. If not, add it to the return dictionary

### Issue 3: Backend error "tool_calls not defined"

**Symptom:**
```
[Chat API] Error: name 'tool_calls' is not defined
```

**Cause:** `tool_calls` variable not initialized

**Fix:**
Add before parsing:
```python
tool_calls = []  # Initialize as empty array
```

### Issue 4: Files not being created

**Symptom:**
- Tool calls detected
- No files created
- No errors

**Cause:** Tool execution logic not running

**Fix:**
1. Check if `_execute_tool_calls()` exists
2. Check if it's being called after parsing
3. Verify tool execution logs

---

## üìä Verification Checklist

After deployment, verify all these pass:

- [ ] **Backend starts successfully**: `bench restart` completes without errors
- [ ] **Function exists**: `grep "def strip_tool_call_blocks" api/__init__.py` returns match
- [ ] **Return includes tool_calls**: `grep "'tool_calls': tool_calls" api/__init__.py` returns match
- [ ] **Test message sent**: Can send "Create a file test.py" in VS Code
- [ ] **Backend detects tool calls**: Logs show "Detected 1 tool call(s)"
- [ ] **Backend cleans content**: Logs show "Cleaned: X ‚Üí Y chars"
- [ ] **Frontend receives tool_calls**: Logs show "Backend returned 1 tool_call(s)"
- [ ] **File is created**: `test.py` exists in workspace
- [ ] **Chat is clean**: No ```tool_call blocks visible in UI
- [ ] **No errors**: No errors in backend or frontend logs

---

## üìù Summary

### What Changes

| Before | After |
|--------|-------|
| ‚ùå Content has tool_call blocks | ‚úÖ Content is clean |
| ‚ùå No tool_calls in response | ‚úÖ tool_calls array included |
| ‚ùå Frontend sees 0 tool calls | ‚úÖ Frontend sees N tool calls |
| ‚ùå Raw JSON in chat | ‚úÖ Clean message in chat |
| ‚ùå Tools don't execute | ‚úÖ Tools execute correctly |

### Lines Added

```python
# 1. Add strip function (~20 lines)
def strip_tool_call_blocks(text): ...

# 2. Initialize tool_calls (~1 line)
tool_calls = []

# 3. Clean content (~5 lines)
if mode == 'agent' and tool_calls:
    clean_content = strip_tool_call_blocks(ai_response_text)
else:
    clean_content = ai_response_text

# 4. Update return (~1 line)
'tool_calls': tool_calls,
```

**Total:** ~30 lines added/modified

### Impact

**Before Fix:**
- User: "Create a file"
- AI: "I'll create... ```tool_call {...}```" ‚Üê User sees raw JSON
- Nothing happens ‚Üê File not created
- User confused

**After Fix:**
- User: "Create a file"
- AI: "I'll create a test.py file for you" ‚Üê Clean message
- File created ‚Üê Tool executes
- User happy

---

## üéØ Next Steps

After deploying this fix:

1. **Test thoroughly** with various tool calls
2. **Monitor logs** for any errors
3. **Check performance** (should be same or better)
4. **Deploy image attachment fix** (if not already done)
5. **Consider other backend enhancements** from analysis

---

## üìû Support

If you encounter issues:

1. **Check logs first**:
   ```bash
   tail -50 ~/frappe-bench/logs/oropendola.ai.log
   ```

2. **Verify code changes**:
   ```bash
   git diff api/__init__.py.backup.* api/__init__.py
   ```

3. **Rollback if needed**:
   ```bash
   cp api/__init__.py.backup.TIMESTAMP api/__init__.py
   bench restart
   ```

4. **Test with curl** (bypass frontend):
   ```bash
   curl -X POST https://oropendola.ai/api/method/ai_assistant.api.chat_completion \
     -H "Content-Type: application/json" \
     -d '{"messages": [...], "mode": "agent"}'
   ```

---

**Document created**: 2025-10-23
**Fix priority**: üî¥ CRITICAL
**Time to deploy**: 30 minutes
**Impact**: HIGH - Fixes entire tool calling system

**Ready to deploy!** üöÄ
